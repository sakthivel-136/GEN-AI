# -*- coding: utf-8 -*-
"""image geneeration

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HMEU64XUdYiclPOst0lPgSnJD4L1oieW

# Install required packages (if not already installed)
"""

!pip install torch torchvision matplotlib

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
import numpy as np

from google.colab import files
uploaded = files.upload()  # Upload `sakthi.zip` when prompted

import zipfile
import os
import shutil

# Step 1: Unzip
with zipfile.ZipFile("sakthi.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/sakthi_raw")

# Step 2: Create final folder
os.makedirs("/content/sakthi/class1", exist_ok=True)

# Step 3: Move valid image files to /content/sakthi/class1
valid_exts = ['.jpg', '.jpeg', '.png', '.bmp', '.webp']
for root, dirs, files in os.walk("/content/sakthi_raw"):
    for file in files:
        if any(file.lower().endswith(ext) for ext in valid_exts):
            full_path = os.path.join(root, file)
            shutil.copy(full_path, "/content/sakthi/class1")

print(f"✅ Total images moved: {len(os.listdir('/content/sakthi/class1'))}")

"""Load and Prepare the Dataset

"""

from torchvision import transforms, datasets
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

dataset = datasets.ImageFolder(root="/content/sakthi", transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

print("✅ Dataset loaded with", len(dataset), "images.")

import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, z_dim=100, img_channels=3, feature_g=64):
        super().__init__()
        self.net = nn.Sequential(
            # Input: Z latent vector
            nn.ConvTranspose2d(z_dim, feature_g * 8, 4, 1, 0),  # (N, f*8, 4, 4)
            nn.BatchNorm2d(feature_g * 8),
            nn.ReLU(True),

            nn.ConvTranspose2d(feature_g * 8, feature_g * 4, 4, 2, 1),  # (N, f*4, 8, 8)
            nn.BatchNorm2d(feature_g * 4),
            nn.ReLU(True),

            nn.ConvTranspose2d(feature_g * 4, feature_g * 2, 4, 2, 1),  # (N, f*2, 16, 16)
            nn.BatchNorm2d(feature_g * 2),
            nn.ReLU(True),

            nn.ConvTranspose2d(feature_g * 2, feature_g, 4, 2, 1),  # (N, f, 32, 32)
            nn.BatchNorm2d(feature_g),
            nn.ReLU(True),

            nn.ConvTranspose2d(feature_g, img_channels, 4, 2, 1),  # (N, 3, 64, 64)
            nn.Tanh()  # Output in [-1, 1]
        )

    def forward(self, x):
        return self.net(x)

class Discriminator(nn.Module):
    def __init__(self, img_channels=3, feature_d=64):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(img_channels, feature_d, 4, 2, 1),  # (N, f, 32, 32)
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(feature_d, feature_d * 2, 4, 2, 1),  # (N, f*2, 16, 16)
            nn.BatchNorm2d(feature_d * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(feature_d * 2, feature_d * 4, 4, 2, 1),  # (N, f*4, 8, 8)
            nn.BatchNorm2d(feature_d * 4),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(feature_d * 4, feature_d * 8, 4, 2, 1),  # (N, f*8, 4, 4)
            nn.BatchNorm2d(feature_d * 8),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(feature_d * 8, 1, 4, 1, 0),  # (N, 1, 1, 1)
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x).view(-1, 1)

import matplotlib.pyplot as plt
import torchvision.utils as vutils

# Show one batch of your real dataset
real_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:64], padding=2, normalize=True).cpu(), (1, 2, 0)))
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Latent space dimension (random noise)
z_dim = 100

# Image dimensions (channels, height, width)
channels_img = 3
image_size = 64

# Models (Use DCGAN versions)
generator = Generator(z_dim=z_dim, img_channels=channels_img).to(device)
discriminator = Discriminator(img_channels=channels_img).to(device)

# Loss function
adversarial_loss = nn.BCELoss()

# Optimizers with betas for better convergence
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

epochs = 15

for epoch in range(epochs):
    for i, (imgs, _) in enumerate(dataloader):  # <-- use 'dataloader' not 'train_loader'
        batch_size = imgs.size(0)

        # Send real images to device
        real_imgs = imgs.to(device)

        # Labels
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # ---------------------
        #  Train Discriminator
        # ---------------------
        optimizer_D.zero_grad()

        # Real loss
        output_real = discriminator(real_imgs).view(-1, 1)
        loss_real = adversarial_loss(output_real, real_labels)

        # Fake images
        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)
        fake_imgs = generator(noise)

        output_fake = discriminator(fake_imgs.detach()).view(-1, 1)
        loss_fake = adversarial_loss(output_fake, fake_labels)

        # Total loss and backward
        d_loss = (loss_real + loss_fake) / 2
        d_loss.backward()
        optimizer_D.step()

        # -----------------
        #  Train Generator
        # -----------------
        optimizer_G.zero_grad()

        output_gen = discriminator(fake_imgs).view(-1, 1)
        g_loss = adversarial_loss(output_gen, real_labels)  # Want generator to fool discriminator

        g_loss.backward()
        optimizer_G.step()

    print(f"Epoch [{epoch+1}/{epochs}]  D Loss: {d_loss.item():.4f}  G Loss: {g_loss.item():.4f}")

import matplotlib.pyplot as plt
from torchvision.utils import make_grid

def show_generated_images(generator, z_dim, num_images=16):
    generator.eval()
    noise = torch.randn(num_images, z_dim, 1, 1).to(device)
    with torch.no_grad():
        fake_imgs = generator(noise)
    fake_imgs = (fake_imgs + 1) / 2  # Rescale to [0,1]
    grid = make_grid(fake_imgs.cpu(), nrow=4, normalize=True)
    plt.figure(figsize=(8,8))
    plt.imshow(grid.permute(1, 2, 0))
    plt.axis("off")
    plt.show()
    generator.train()

from PIL import Image
from IPython.display import display

# Save the generated image
from torchvision.utils import save_image

noise = torch.randn(64, z_dim, 1, 1).to(device)
with torch.no_grad():
    gen_imgs = generator(noise)
    gen_imgs = (gen_imgs + 1) / 2  # Normalize to [0,1]

save_image(gen_imgs, "generated_output.png", nrow=8)

# ✅ View the image inside the notebook
img = Image.open("generated_output.png")
display(img)