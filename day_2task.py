# -*- coding: utf-8 -*-
"""DAY-2TASK

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jSEX-_KTBRulEDg3WysJauH9njFD3qL2
"""

!pip install transformers

"""# facebook/bart-large-cnn for Text Summarization"""

from transformers import BartTokenizer, BartForConditionalGeneration

# Load tokenizer and model
bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Input text
text = """K. Kamarajar, fondly known as the "Kingmaker" and "Kalvi Thanthai" (Father of Education), was a visionary leader who transformed Tamil Nadu through his dedication to education and simplicity. Born into a humble background, he rose to become the Chief Minister and played a crucial role in India's freedom struggle. Kamarajar introduced free education, mid-day meal schemes, and opened numerous schools, ensuring education reached even the poorest children. He lived a life of honesty and service, refusing luxury for the welfare of the people. His legacy continues to inspire generations to lead with integrity, compassion, and commitment to social upliftment."""

# Tokenize and summarize
inputs = bart_tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)
summary_ids = bart_model.generate(inputs['input_ids'], max_length=100, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)
summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)

print("\n[BART Summary]:", summary)

"""# **google/flan-t5-base for Prompt-based Text Generation**"""

from transformers import T5Tokenizer, T5ForConditionalGeneration

# Load tokenizer and model
flan_tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-base")
flan_model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-base")

# Prompt
prompt = "Summarize: " + text

# Tokenize and generate
inputs = flan_tokenizer(prompt, return_tensors="pt")
outputs = flan_model.generate(**inputs, max_length=100, num_beams=4, early_stopping=True)
generated_summary = flan_tokenizer.decode(outputs[0], skip_special_tokens=True)

print("\n[FLAN-T5 Summary]:", generated_summary)